name: 'Falco Action Analyze'
description: 'Analyze Workflows with Falco'
author: 'The Falco Authors'
inputs:
  custom-rule-file:
    description: 'Custom rule file'
    type: string
    default: ''
    required: false
  falco-version:
    description: 'Falco version to use'
    required: false
    default: 'latest'
  extract-connections:
    description: 'Extract connections'
    type: boolean
    default: true
    required: false
  extract-written-files:
    description: 'Extract written files'
    type: boolean
    default: false
    required: false
  extract-processes:
    description: 'Extract processes'
    type: boolean
    default: true
    required: false
  extract-dns:
    description: 'Extract DNS'
    type: boolean
    default: true
    required: false
  extract-containers:
    description: 'Extract containers'
    type: boolean
    default: true
    required: false
  extract-chisels:
    description: 'Extract chisels'
    type: boolean
    default: false
    required: false
  extract-hashes:
    description: 'Extract hashes'
    type: boolean
    default: false
    required: false
  filters-config:
    description: 'Filter configuration file'
    type: string
    default: 'src/filters.config'
    required: false
  openai-model:
    description: "Open AI model to use for summary"
    type: string
    default: "gpt-3.5-turbo"
    required: false
  openai-user-prompt:
    description: "Message to send to OpenAI"
    type: string
    default: ''
    required: false
  verbose:
    description: 'Enable verbose logs'
    type: boolean
    required: false
    default: false
runs:
  using: 'composite'
  steps:
  - name: Download capture
    uses: actions/download-artifact@fa0a91b85d4f404e444e00e005971372dc801d16 # v4.1.8
    with:
      name: capture
      path: /tmp

  - name: Download hashes
    if: ${{ inputs.extract-hashes == 'true' }}
    uses: actions/download-artifact@fa0a91b85d4f404e444e00e005971372dc801d16 # v4.1.8
    with:
      name: hashes
      path: /tmp
  
  - name: Start Falco in capture mode
    shell: bash
    env:
      VERBOSE: ${{ inputs.verbose }}
      CUSTOM_RULE_FILE: ${{ inputs.custom-rule-file }}
    id: start_falco
    run: |
      if [ "$VERBOSE" = "true" ]; then
        set -x
        stat /tmp/capture.scap
      fi

      echo "{name}={value}" >> $GITHUB_OUTPUT
      if [ "${{ inputs.filters-config }}" != "src/filters.config" ]; then
        echo "Using custom config"
        echo "config_file=${{ inputs.filters-config }}" >> $GITHUB_OUTPUT
      else
        echo "Using default config"
        echo "config_file=${{github.action_path}}/${{inputs.filters-config}}" >> $GITHUB_OUTPUT
      fi

      MOUNT_CUSTOM_RULE=""
      if [[ -f "$CUSTOM_RULE_FILE" ]]; then
        if [ "$VERBOSE" = "true" ]; then
          echo "Loading custom rules from $CUSTOM_RULE_FILE"
        fi
        MOUNT_CUSTOM_RULE="-v $CUSTOM_RULE_FILE:/etc/falco/rules.d/custom_rules.yaml"
      fi

      docker run --rm --name falco \
        -v /tmp:/tmp \
        $MOUNT_CUSTOM_RULE \
        falcosecurity/falco-no-driver:${{ inputs.falco-version }} falco -o "json_output=true" -o "file_output.enabled=true" -o "file_output.keep_alive=false" -o "file_output.filename=/tmp/falco_events.json" -o "engine.kind=replay" -o "engine.replay.capture_file=/tmp/capture.scap" 

  - name: Extract outbound connections
    if: ${{ inputs.extract-connections == 'true' }}
    shell: bash
    env:
      VERBOSE: ${{ inputs.verbose }}
    run: |
      if [ "$VERBOSE" = "true" ]; then
        set -x
      fi
      OUTBOUND_FILTER="(((evt.type = connect and evt.dir=<) or (evt.type in (sendto,sendmsg,sendmmsg) and evt.dir=< and fd.l4proto != tcp and fd.connected=false and fd.name_changed=true)) and (fd.typechar = 4 or fd.typechar = 6) and (fd.ip != \"0.0.0.0\" and fd.net != \"127.0.0.0/8\" and not fd.snet in (\"10.0.0.0/8\", \"172.16.0.0/12\", \"192.168.0.0/16\")))" 
      CUSTOM_FILTERS=$(jq -r '.outbound_connections // [] | .[] | "and not (\(.condition) )"' "${{ steps.start_falco.outputs.config_file }}" | sed "s/'/\"/g" | tr '\n' ' ' | sed 's/[[:space:]]*$//')
      if [ "${{ inputs.verbose }}" = "true" ]; then
        echo "Custom filters: $CUSTOM_FILTERS"
      fi
      OUTBOUND_OUTPUT="%evt.time,%fd.sip,%fd.sport,%proc.name,%proc.exepath,%user.name"
      ${{github.action_path}}/../common/run_sysdig.sh filter "/tmp/capture.scap" "$OUTBOUND_FILTER $CUSTOM_FILTERS" "$OUTBOUND_OUTPUT" "/tmp/outbound.txt"

  - name: Extract written files
    if: ${{ inputs.extract-written-files == 'true' }}
    shell: bash
    env:
      VERBOSE: ${{ inputs.verbose }}
    run: |
      if [ "$VERBOSE" = "true" ]; then
        set -x
      fi
      FILE_WRITTEN_FILTER="evt.type in (open,openat,openat2) and evt.is_open_write=true and fd.typechar=\"f\" and fd.num>=0"
      CUSTOM_FILTERS=$(jq -r '.written_files // [] | .[] | "and not (\(.condition) )"' "${{ steps.start_falco.outputs.config_file }}" | sed "s/'/\"/g" | tr '\n' ' ' | sed 's/[[:space:]]*$//')
      if [ "${{ inputs.verbose }}" = "true" ]; then
        echo "Custom filters: $CUSTOM_FILTERS"
      fi
      FILE_WRITTEN_OUTPUT="%evt.time,%fd.name,%proc.name,%proc.exepath,%proc.pexepath,%user.name"
      ${{github.action_path}}/../common/run_sysdig.sh filter "/tmp/capture.scap" "$FILE_WRITTEN_FILTER $CUSTOM_FILTERS" "$FILE_WRITTEN_OUTPUT" "/tmp/files_written.txt"

  - name: Extract processes information
    if: ${{ inputs.extract-processes == 'true' }}
    shell: bash
    env:
      VERBOSE: ${{ inputs.verbose }}
    run: |
      if [ "$VERBOSE" = "true" ]; then
        set -x
      fi
      PROC_FILTER="evt.type in (execve, execveat) and evt.dir=< and evt.arg.res=0"
      CUSTOM_FILTERS=$(jq -r '.processes // [] | .[] | "and not (\(.condition) )"' "${{ steps.start_falco.outputs.config_file }}" | sed "s/'/\"/g" | tr '\n' ' ' | sed 's/[[:space:]]*$//')
      if [ "${{ inputs.verbose }}" = "true" ]; then
        echo "Custom filters: $CUSTOM_FILTERS"
      fi
      PROC_FILTER_OUTPUT="%evt.time,%proc.name,%proc.exepath,%proc.pname,%proc.pexepath,%user.name"
      ${{github.action_path}}/../common/run_sysdig.sh filter "/tmp/capture.scap" "$PROC_FILTER $CUSTOM_FILTERS" "$PROC_FILTER_OUTPUT" "/tmp/proc.txt"

  - name: Extract chisels information for summary
    if: ${{ inputs.extract-chisels == 'true' }}
    shell: bash
    env:
      VERBOSE: ${{ inputs.verbose }}
    run: |
      if [ "$VERBOSE" = "true" ]; then
        set -x
      fi
      ${{github.action_path}}/../common/run_sysdig.sh chisel "/tmp/capture.scap" "udp_extract.lua" "/tmp/udp_extract.txt"
      ${{github.action_path}}/../common/run_sysdig.sh chisel "/tmp/capture.scap" "topconns.lua" "/tmp/top_connection.txt"
      ${{github.action_path}}/../common/run_sysdig.sh chisel "/tmp/capture.scap" "topprocs_net.lua" "/tmp/topprocs_net.txt"

  - name: Extract DNS domains
    if: ${{ inputs.extract-dns == 'true' }}
    shell: bash
    env:
      VERBOSE: ${{ inputs.verbose }}
    run: |
      if [ "$VERBOSE" = "true" ]; then
        set -x
      fi
      DNS_FILTER="evt.type in (recvmsg,read,recv,recvfrom) and fd.rport=53 and fd.l4proto=udp"
      DNS_OUTPUT="%evt.buffer"
      ${{github.action_path}}/../common/run_sysdig.sh filter "/tmp/capture.scap" "$DNS_FILTER" "$DNS_OUTPUT" "/tmp/buffers.txt"
      if [[ ! -s /tmp/buffers.txt ]]; then
        echo "Warning: No contacted DNS domains found"
        exit 0
      fi
      cat /tmp/buffers.txt | grep -o -E "[a-zA-Z0-9-]+(\.[a-zA-Z0-9-]+)*(\.[a-zA-Z]{2,})" | grep -E -v "NULL" | grep -E -v "ns." | grep -E -v "\->" | grep -E -v "evt.buffer" | sort | uniq > /tmp/dns_extract.txt
      if [[ "${{ inputs.verbose }}" == "true" ]]; then
        echo "Extracted DNS domains" && cat /tmp/dns_extract.txt
      fi
      while read -r line; do
        echo "{ \"domain\": \"$line\" }"
      done < /tmp/dns_extract.txt > /tmp/dns_extract_json.txt
  
  - name: Extract executables' hash
    if: ${{ inputs.extract-hashes == 'true' }}
    shell: bash
    env:
      VERBOSE: ${{ inputs.verbose }}
    run: |    
      if [ "$VERBOSE" = "true" ]; then
        set -x
      fi  
      cat /tmp/proc.txt| jq '."proc.exepath"' | tr -d "\"" | while read -r file; do
        if [ -f "$file" ]; then
            line=$(sha256sum "$file")
            sha=$(echo "$line" | awk '{print $1}')
            file=$(echo "$line" | awk '{print $2}')
            echo "{ \"sha256\": \"$sha\", \"filename\": \"$file\" }"
        else
            echo "Warning: File $file does not exist anymore when extracting its SHA256 hash" >&2
        fi 
      done > /tmp/hashes.txt

      sort -u -o /tmp/hashes.txt /tmp/hashes.txt
  
  - name: Extract docker container images
    if: ${{ inputs.extract-containers == 'true' }}
    shell: bash
    env:
      VERBOSE: ${{ inputs.verbose }}
    run: |
      if [ "$VERBOSE" = "true" ]; then
        set -x
      fi
      CONTAINER_FILTER="evt.type=container"
      CONTAINER_OUTPUT="%container.name,%container.image.repository"
      ${{github.action_path}}/../common/run_sysdig.sh filter "/tmp/capture.scap" "$CONTAINER_FILTER" "$CONTAINER_OUTPUT" "/tmp/containers.txt"
      if [[ -s /tmp/containers.txt ]]; then
        sort -u -o /tmp/containers.txt /tmp/containers.txt
        echo "Sorted /tmp/containers.txt"
      else
        echo "File /tmp/containers.txt is empty. Impossible to sort it."
      fi
      
  - name: Retrieve Job Info using GitHub API
    shell: bash
    env:
      RUN_ID: ${{ github.run_id }}
      REPO: ${{ github.repository }}
      GITHUB_TOKEN: ${{ github.token }}
      VERBOSE: ${{ inputs.verbose }}
    run: |
      if [ "$VERBOSE" = "true" ]; then
        set -x
      fi
      echo "Retrieving details for run_id=$RUN_ID"
      curl -s -H "Authorization: Bearer $GITHUB_TOKEN" \
        -H "Accept: application/vnd.github.v3+json" \
        https://api.github.com/repos/$REPO/actions/runs/$RUN_ID/jobs > jobs.json
      
      # Parse JSON and retrieve step info with timestamps
      echo "Job details:"
      jq -c '.jobs[] | {job_id: .id, job_name: .name, steps: .steps[] | {name: .name, started_at: .started_at, completed_at: .completed_at, status: .status}}' jobs.json > steps.json

      if [[ "${{ inputs.verbose }}" == "true" ]]; then
        cat steps.json
      fi
      mv steps.json /tmp/steps.json
      
  - name: Build summary
    shell: bash
    env:
      RUN_ID: ${{ github.run_id }}
      REPO: ${{ github.repository }}
      VERBOSE: ${{ inputs.verbose }}
    run: |
      if [ "$VERBOSE" = "true" ]; then
        set -x
      fi
      python3 -m pip install -r ${{github.action_path}}/../common/requirements.txt
      echo "# Report Details" >> /tmp/report_output.md
      # Falco events
      if [[ -s /tmp/falco_events.json ]]; then
        echo "Printing triggered rules in Job summary"
        echo "## Falco Events" >> /tmp/report_output.md
        content=$(python3 ${{github.action_path}}/../common/falco_events_to_md.py /tmp/falco_events.json /tmp/steps.json)
        echo "$content" >> /tmp/report_output.md
      
        if ${{ github.event_name == 'pull_request' }}; then
          echo "Creating PR comment with triggered signatures"
          FILE_CONTENT=$(echo "$content" | sed 's/\\/\\\\/g' | sed ':a;N;$!ba;s/\n/\\n/g')
          curl -X POST \
            -H "Authorization: token $GITHUB_TOKEN" \
            -H "Content-Type: application/json" \
            -d "{\"body\": \"***Falco Rules*** \\n\\n ${FILE_CONTENT} \\n\\n Find out more at https://github.com/$REPO/actions/runs/$RUN_ID\"}" \
            https://api.github.com/repos/${{ github.repository }}/issues/${{ github.event.pull_request.number }}/comments
        fi
      fi

      # Processes
      if [[ -s /tmp/proc.txt ]]; then
        echo "## Processes" >> /tmp/report_output.md
        python3 ${{github.action_path}}/src/json_to_md.py /tmp/proc.txt >> /tmp/report_output.md
      fi

      # Written files
      if [[ -s /tmp/files_written.txt ]]; then
        echo "## Written Files" >> /tmp/report_output.md
        python3 ${{github.action_path}}/src/json_to_md.py /tmp/files_written.txt >> /tmp/report_output.md
      fi

      # Contacted IPs
      if [[ -s /tmp/outbound.txt ]]; then
        echo "## Contacted IPs" >> /tmp/report_output.md
        if ${{ env.VT_API_KEY != '' }}; then
          echo "Querying VirusTotal for IPs"
          python3 ${{github.action_path}}/src/integrations/virustotal/vt_script.py /tmp/outbound.txt --mode ips >> /tmp/outbound_vt.txt
          python3 ${{github.action_path}}/src/json_to_md.py /tmp/outbound_vt.txt >> /tmp/report_output.md
        else
          python3 ${{github.action_path}}/src/json_to_md.py /tmp/outbound.txt >> /tmp/report_output.md
        fi
      fi

      # DNS
      if [[ -s /tmp/dns_extract_json.txt ]]; then
        echo "## Contacted DNS Domains" >> /tmp/report_output.md
        python3 ${{github.action_path}}/src/json_to_md.py /tmp/dns_extract_json.txt >> /tmp/report_output.md
      fi

      # Containers
      if [[ -s /tmp/containers.txt ]]; then
        echo "## Containers" >> /tmp/report_output.md
        python3 ${{github.action_path}}/src/json_to_md.py /tmp/containers.txt >> /tmp/report_output.md
      fi

      # Hashes
      if [[ -s /tmp/hashes.txt ]]; then
        echo "## Executable Hashes" >> /tmp/report_output.md
        if ${{ env.VT_API_KEY != '' }}; then
          echo "Querying VirusTotal for hashes"
          python3 ${{github.action_path}}/src/integrations/virustotal/vt_script.py /tmp/hashes.txt --mode hashes >> /tmp/hashes_vt.txt
          python3 ${{github.action_path}}/src/json_to_md.py /tmp/hashes_vt.txt >> /tmp/report_output.md
        else
          python3 ${{github.action_path}}/src/json_to_md.py /tmp/hashes.txt >> /tmp/report_output.md
        fi
      fi  

      # Top Connections
      if [[ -s /tmp/top_connection.txt ]]; then
        echo "## Top Connections" >> /tmp/report_output.md
        python3 ${{github.action_path}}/src/capture_to_md.py /tmp/top_connection.txt >> /tmp/report_output.md
      fi

      echo "" >> /tmp/report_output.md

      # If OpenAI API key is set, create a brief summary using OpenAI
      if ${{ env.OPENAI_API_KEY != '' }}; then
        echo "Creating Report Summary using OpenAI"
        echo "# Report Summary" >> /tmp/report_openai.md
        echo "Installing python dependencies"
        python3 -m pip install -r ${{github.action_path}}/src/integrations/openai/requirements.txt
        echo "Calling OpenAI APIs for summary"
        if ${{inputs.openai-user-prompt == ''}}; then
          python3 ${{github.action_path}}/src/integrations/openai/create_summary.py /tmp/report_output.md --model "${{inputs.openai-model}}" >> /tmp/report_openai.md
        else
          python3 ${{github.action_path}}/src/integrations/openai/create_summary.py /tmp/report_output.md --model "${{inputs.openai-model}}" --user_input "${{inputs.openai-user-prompt}}" >> /tmp/report_openai.md
        fi
        echo -e "\n" >> /tmp/report_openai.md
        cat /tmp/report_output.md >> /tmp/report_openai.md
        mv /tmp/report_openai.md /tmp/report_output.md
      fi

      echo "Appending report to github summary"
      cat /tmp/report_output.md >> $GITHUB_STEP_SUMMARY
